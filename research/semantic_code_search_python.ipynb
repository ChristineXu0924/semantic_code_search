{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb54b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301420e6",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_py = load_dataset(\"code_search_net\", \"python\")\n",
    "train_py = pd.DataFrame(dataset_py['train'])\n",
    "\n",
    "ground_truth = pd.read_csv('annotationStore.csv')\n",
    "gt_py = ground_truth[ground_truth['Language'] == 'Python']\n",
    "\n",
    "merged_py = gt_py.merge(train_py, left_on = 'GitHubUrl', right_on = 'func_code_url')\n",
    "merged_py.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f53628",
   "metadata": {},
   "source": [
    "## Identifier + Doc embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_doc = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sample_doc = train_py['func_name'] + \" \" + train_py['func_documentation_string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e4da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_doc_emb = model_doc.encode(query, convert_to_tensor=True)\n",
    "hits = util.semantic_search(que_doc_emb, doc_emb)[0]\n",
    "top_hits = hits[:10]\n",
    "# cdist_score = cdist(que_doc_emb, doc_emb)\n",
    "# top_hits = torch.topk(cdist_score, k=top_3)\n",
    "rank = 1\n",
    "que_doc_df = pd.DataFrame()\n",
    "que_doc_score = []\n",
    "que_doc_url = []\n",
    "que_doc_rank = []\n",
    "for top_hit in top_hits:\n",
    "    print(\"Cossim: {:.2f}\".format(top_hit['score']))\n",
    "    print(f\"Rank: {rank}\")\n",
    "    print(train_py.iloc[top_hit['corpus_id']]['func_code_url'])\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    que_doc_score.append(top_hit['score'])\n",
    "    que_doc_url.append(train_py.iloc[top_hit['corpus_id']]['func_code_url'])\n",
    "    que_doc_rank.append(rank)\n",
    "    rank += 1\n",
    "\n",
    "que_doc_df['score'] = que_doc_score\n",
    "que_doc_df['rank'] = que_doc_rank\n",
    "que_doc_df['url'] = que_doc_url\n",
    "que_doc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af699287",
   "metadata": {},
   "source": [
    "## Code Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7c4bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_code = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "sample_code = train_py['whole_func_string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b414540",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_code_emb = model_code.encode(query, convert_to_tensor=True)\n",
    "hits = util.semantic_search(que_code_emb, code_emb)[0]\n",
    "top_hits = hits[:3]\n",
    "\n",
    "for top_hit in top_hits:\n",
    "    print(\"Cossim: {:.2f}\".format(top_hit['score']))\n",
    "    print(merged.iloc[top_hit['corpus_id']]['func_code_url'])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5f7210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e032a6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b941a9cc",
   "metadata": {},
   "source": [
    "## Tryouts - Pretrained CodeBERT(currently only on python)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e2a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d82e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer_code = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model_code = RobertaModel.from_pretrained(\"demo/python_model\").to(device)\n",
    "\n",
    "# Load the data\n",
    "# train_data = pd.read_csv('merged_py.csv')  # only on the ones with query and code pairs\n",
    "train_data = train_py\n",
    "sample_code = list(train_data['whole_func_string'])\n",
    "\n",
    "# Tokenize and encode the query\n",
    "encoded_query = tokenizer_code(query, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
    "with torch.no_grad():\n",
    "    query_vec = model_code(**encoded_query)[1]  # Get the pooled output\n",
    "\n",
    "code_vecs = []\n",
    "codes = []\n",
    "\n",
    "# Tokenize and encode the code snippets\n",
    "for code in sample_code:\n",
    "    encoded_code = tokenizer_code(code, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        cur_code_vec = model_code(**encoded_code)[1]  # Get the pooled output\n",
    "    code_vecs.append(cur_code_vec)\n",
    "    codes.append(code)\n",
    "\n",
    "# Concatenate the code vectors and move to the same device as the query vector\n",
    "code_vecs = torch.cat(code_vecs).to(device)\n",
    "\n",
    "# Calculate the cosine similarities\n",
    "scores = torch.einsum(\"ab,cb->ac\", query_vec, code_vecs)\n",
    "scores = torch.softmax(scores, -1)\n",
    "\n",
    "# Get the top 5 scores and their indices\n",
    "top_scores, top_indices = torch.topk(scores[0], 5, largest=True)\n",
    "\n",
    "# Retrieve the top 5 most relevant code snippets using the indices\n",
    "top_code_snippets = [sample_code[index] for index in top_indices.cpu().numpy()]\n",
    "\n",
    "# Print the results\n",
    "for score, snippet in zip(top_scores, top_code_snippets):\n",
    "    print(f\"Relevance Score: {score.item()}\\nCode Snippet: {snippet}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1812c176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "763e91c6",
   "metadata": {},
   "source": [
    "# Evaluation - nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ea418",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = merged_py[merged_py['Query'] == query]\n",
    "final = target.merge(que_doc_df, left_on = 'GitHubUrl', right_on = 'url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4129e395",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MRR = 1/final['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d56484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check nDCG calculation\n",
    "# dataframe: final\n",
    "def dcg(data, length, rank, relevance):\n",
    "    scorces = []\n",
    "    answers_len = len(data)\n",
    "    \n",
    "    for i in range(length):\n",
    "        if i+1 in data['rank'].values:\n",
    "            cur_data = data[data['rank'] == i+1]\n",
    "            gain = cur_data['Relevance']\n",
    "        else:\n",
    "            gain = 0\n",
    "        score = gain / np.log2(i+2)\n",
    "        scores.append(score)\n",
    "    return sum(scores)\n",
    "\n",
    "\n",
    "# dataframe: merged, expected result, check how many expected results are in the train\n",
    "# and should be returned\n",
    "def idcg(data, query, length):\n",
    "    scores = []\n",
    "    expected = data[data['Query'] == query].sort_values(by ='Relevance', ascending=False)\n",
    "    answers_len = len(expected)\n",
    "    \n",
    "    cal_length = min(answers_len, length)\n",
    "    for i in range(cal_length):\n",
    "        if i >= len(answers_len):\n",
    "            gain = 0\n",
    "        else:\n",
    "            gain = expected.iloc[i]['Relevance']\n",
    "        score = gain / np.log2(i+2)\n",
    "        scores.append(score)\n",
    "    return sum(scores)\n",
    "\n",
    "dcg_score = dcg(final, 3)\n",
    "idcg_score = idcg(merged_py, 3)\n",
    "ndcg_score = dcg_score/idcg_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
