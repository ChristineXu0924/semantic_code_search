{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "840b4ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f729405fe30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up the enviornment and random seed for reproducibility\n",
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import string\n",
    "# !pip install sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "# set random seed\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.cuda.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b33beb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# # check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bdae377",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"priority queue\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6882fa",
   "metadata": {},
   "source": [
    "# Load in the CodeSearchNet Python sub-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22e7185d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jix028/.local/lib/python3.9/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(990, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_py = load_dataset(\"code_search_net\", \"python\")\n",
    "train_py = pd.DataFrame(dataset_py['train'])\n",
    "\n",
    "ground_truth = pd.read_csv('annotationStore.csv')\n",
    "gt_py = ground_truth[ground_truth['Language'] == 'Python']\n",
    "\n",
    "merged_py = gt_py.merge(train_py, left_on = 'GitHubUrl', right_on = 'func_code_url')\n",
    "merged_py.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdc8ff7",
   "metadata": {},
   "source": [
    "# Indentifier + Doc embedding with all-MiniLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e3e9c5",
   "metadata": {},
   "source": [
    "- The natural language part was designed as a combination of the function identifier and docstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a07b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_doc = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sample_doc = train_py['func_name'] + \" \" + train_py['func_documentation_string']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b07813",
   "metadata": {},
   "source": [
    "**Embed the documentation part and save it as 'doc_emb.pt' for easier future access**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c13bd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_emb = model_doc.encode(sample_doc, convert_to_tensor=True)\n",
    "# torch.save(doc_emb, 'doc_emb.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca9a15d",
   "metadata": {},
   "source": [
    "**Loading in the saved embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cc0b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_emb = torch.load('doc_emb.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d16bffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate similarity scores between query embedding and doc\n",
    "## embedding, adding weight into the final score for combination purpose.\n",
    "def weighted_doc(query, k, weight, param=3):\n",
    "    que_doc_emb = model_doc.encode(query, convert_to_tensor=True)\n",
    "    hits = util.semantic_search(que_doc_emb, doc_emb)[0]\n",
    "    if param*k > len(hits):\n",
    "        top_hits = hits\n",
    "        num_out = len(hits)\n",
    "    else:\n",
    "        top_hits = hits[:param*k]\n",
    "        num_out = param*k\n",
    "\n",
    "    rank = 1\n",
    "    que_doc_df = pd.DataFrame()\n",
    "    que_doc_score = []\n",
    "    que_doc_url = []\n",
    "    que_doc_rank = []\n",
    "    for top_hit in top_hits:\n",
    "        que_doc_score.append(weight*float(top_hit['score']))\n",
    "        que_doc_url.append(train_py.iloc[top_hit['corpus_id']]['func_code_url'])\n",
    "        que_doc_rank.append(rank)\n",
    "        rank += 1\n",
    "    que_doc_df['score'] = que_doc_score\n",
    "    que_doc_df['url'] = que_doc_url\n",
    "    return que_doc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80e05e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.763506</td>\n",
       "      <td>https://github.com/flaviogrossi/sockjs-cyclone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.745125</td>\n",
       "      <td>https://github.com/Jaymon/prom/blob/b7ad2c259e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.736036</td>\n",
       "      <td>https://github.com/Jaymon/prom/blob/b7ad2c259e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.731232</td>\n",
       "      <td>https://github.com/keon/algorithms/blob/4d6569...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.718924</td>\n",
       "      <td>https://github.com/SKA-ScienceDataProcessor/in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.715550</td>\n",
       "      <td>https://github.com/Erotemic/utool/blob/3b27e1f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.703601</td>\n",
       "      <td>https://github.com/SKA-ScienceDataProcessor/in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.702734</td>\n",
       "      <td>https://github.com/nerdvegas/rez/blob/1d3b846d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.699726</td>\n",
       "      <td>https://github.com/pinax/django-mailer/blob/12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.698709</td>\n",
       "      <td>https://github.com/limpyd/redis-limpyd-jobs/bl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                                                url\n",
       "0  0.763506  https://github.com/flaviogrossi/sockjs-cyclone...\n",
       "1  0.745125  https://github.com/Jaymon/prom/blob/b7ad2c259e...\n",
       "2  0.736036  https://github.com/Jaymon/prom/blob/b7ad2c259e...\n",
       "3  0.731232  https://github.com/keon/algorithms/blob/4d6569...\n",
       "4  0.718924  https://github.com/SKA-ScienceDataProcessor/in...\n",
       "5  0.715550  https://github.com/Erotemic/utool/blob/3b27e1f...\n",
       "6  0.703601  https://github.com/SKA-ScienceDataProcessor/in...\n",
       "7  0.702734  https://github.com/nerdvegas/rez/blob/1d3b846d...\n",
       "8  0.699726  https://github.com/pinax/django-mailer/blob/12...\n",
       "9  0.698709  https://github.com/limpyd/redis-limpyd-jobs/bl..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_doc(query, 5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aafd734",
   "metadata": {},
   "source": [
    "# Code embedding with GraphCodeBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba50f5b",
   "metadata": {},
   "source": [
    "Sources:\n",
    "- https://github.com/microsoft/CodeBERT/tree/master/GraphCodeBERT/codesearch\n",
    "- https://openreview.net/pdf?id=jLoC4ez43PZ (GRAPHCODEBERT: PRE-TRAINING CODE REPRESENTATIONS WITH DATA FLOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c06f46aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5b03d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = train_py\n",
    "sample_code = list(train_data['whole_func_string'])\n",
    "sample_url = train_data['func_code_url']\n",
    "sample_document = list(train_data['func_documentation_string'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba67952",
   "metadata": {},
   "source": [
    "### ##________The GraphCodeBERT embedding process. Skip to load trained embeddings directionly______##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53adf2b",
   "metadata": {},
   "source": [
    "Clean the code string following the training idea of GraphCodeBERT:\n",
    "- Remove all the docstrings and comments in the code string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ef5be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## perform clean code, removing documentation and comments\n",
    "cleaned_codes = []\n",
    "for codestr in sample_code:\n",
    "    pattern_doc = r'\\\"\\\"\\\"(.*?)\\\"\\\"\\\"'\n",
    "    pattern_comm = r'#[^\\n]*'\n",
    "    clean_code = re.sub(pattern_doc, '', codestr, flags=re.DOTALL)\n",
    "    clean_code = re.sub(pattern_comm, '', clean_code, flags=re.DOTALL)\n",
    "\n",
    "    cleaned_codes.append(clean_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63825763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer_code = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model_code = RobertaModel.from_pretrained(\"demo/python_model\").to(device)\n",
    "\n",
    "# Load the data\n",
    "train_data = train_py\n",
    "sample_code = cleaned_codes\n",
    "\n",
    "# Tokenize and encode the query\n",
    "encoded_query = tokenizer_code(query, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
    "with torch.no_grad():\n",
    "    query_vec = model_code(**encoded_query)[1]  # Get the pooled output\n",
    "\n",
    "code_vecs = []\n",
    "codes = []\n",
    "\n",
    "# Tokenize and encode the code snippets\n",
    "for code in sample_code:\n",
    "    encoded_code = tokenizer_code(code, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        cur_code_vec = model_code(**encoded_code)[1]  # Get the pooled output\n",
    "    code_vecs.append(cur_code_vec)\n",
    "    codes.append(code)\n",
    "\n",
    "# Concatenate the code vectors and move to the same device as the query vector\n",
    "code_vecs = torch.cat(code_vecs).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3c09fe",
   "metadata": {},
   "source": [
    "Store the embedding into `clean_code_emb.pt` for faster future access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d1e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(code_vecs, 'clean_code_emb.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41d1d96",
   "metadata": {},
   "source": [
    "###  ## ______________ Load in the embedded code matrix_________##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e7c30a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "py_emb_mat = torch.load('clean_code_emb.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75012a1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3143, -0.0544, -0.4870,  ..., -0.8017,  0.0938, -0.1380],\n",
       "        [ 0.2373, -0.2394, -0.3631,  ..., -0.1189,  0.1311, -0.5173],\n",
       "        [ 0.2249, -0.2622, -0.0532,  ..., -0.1795,  0.2224, -0.4343],\n",
       "        ...,\n",
       "        [-0.5379,  0.2046, -0.6276,  ..., -0.7098, -0.0771, -0.4519],\n",
       "        [-0.0073, -0.1181, -0.7433,  ..., -0.4311,  0.3418, -0.2338],\n",
       "        [ 0.0192, -0.2119, -0.8511,  ..., -0.4541,  0.5451, -0.4459]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_emb_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "658de188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer_code = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model_code = RobertaModel.from_pretrained(\"python_model\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "153dddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the similarity score (cosine sim) between query embedding\n",
    "## and code embeddings. Add weight into the score for combining with\n",
    "## doc score.\n",
    "\n",
    "def weighted_code(query, emb_mat, k, weight, param=3):\n",
    "    \"\"\" \n",
    "    Inputs: natural language query, the stored embedded matrix for training code.\n",
    "    Outputs: a dataframe with the top-k matches from the training code \n",
    "    \n",
    "    \"\"\"\n",
    "    # Tokenize and encode the query\n",
    "    encoded_query = tokenizer_code(query, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        query_vec = model_code(**encoded_query)[1] # Get the pooled output\n",
    "    \n",
    "    code_vecs = emb_mat\n",
    "    \n",
    "    # Calculate the cosine similarities\n",
    "    query_vec - query_vec.view(1,-1).expand_as(code_vecs)\n",
    "    scores = nn.functional.cosine_similarity(query_vec, code_vecs, dim=1)\n",
    "    \n",
    "    \n",
    "    # Get the top 5 scores and their indices\n",
    "    top_scores, top_indices = torch.topk(scores, param*k, largest=True)\n",
    "    \n",
    "    \n",
    "    # Retrieve the top 5 most relevant code snippets using the indices\n",
    "    top_code_snippets = [sample_url[index] for index in top_indices.cpu().numpy()]\n",
    "    \n",
    "    rank = 1\n",
    "    que_code_df = pd.DataFrame()\n",
    "    que_code_score = []\n",
    "    que_code_url = []\n",
    "    que_code_rank = []\n",
    "    \n",
    "    for score,url in zip(top_scores, top_code_snippets):\n",
    "        que_code_score.append(weight*float(score.cpu()))\n",
    "        que_code_url.append(url)\n",
    "        que_code_rank.append(rank)\n",
    "        rank += 1\n",
    "    \n",
    "    que_code_df['score'] = que_code_score\n",
    "    que_code_df['url'] = que_code_url\n",
    "    \n",
    "    return que_code_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "356fd701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.765143</td>\n",
       "      <td>https://github.com/hubo1016/vlcp/blob/23905522...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.738386</td>\n",
       "      <td>https://github.com/fchauvel/MAD/blob/806d51748...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.723233</td>\n",
       "      <td>https://github.com/rackerlabs/rackspace-python...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.722229</td>\n",
       "      <td>https://github.com/rfk/threading2/blob/7ec234d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.713473</td>\n",
       "      <td>https://github.com/calston/rhumba/blob/05e3cbf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.705459</td>\n",
       "      <td>https://github.com/istresearch/scrapy-cluster/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.705304</td>\n",
       "      <td>https://github.com/calston/rhumba/blob/05e3cbf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.703363</td>\n",
       "      <td>https://github.com/limpyd/redis-limpyd-jobs/bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.700093</td>\n",
       "      <td>https://github.com/calston/rhumba/blob/05e3cbf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.697995</td>\n",
       "      <td>https://github.com/axialmarket/fsq/blob/43b84c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.695321</td>\n",
       "      <td>https://github.com/ViiSiX/FlaskRedislite/blob/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.694200</td>\n",
       "      <td>https://github.com/bioidiap/gridtk/blob/9e3291...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.693718</td>\n",
       "      <td>https://github.com/ejeschke/ginga/blob/a78c893...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.692426</td>\n",
       "      <td>https://github.com/knipknap/exscript/blob/7271...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.691984</td>\n",
       "      <td>https://github.com/closeio/tasktiger/blob/59f8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score                                                url\n",
       "0   0.765143  https://github.com/hubo1016/vlcp/blob/23905522...\n",
       "1   0.738386  https://github.com/fchauvel/MAD/blob/806d51748...\n",
       "2   0.723233  https://github.com/rackerlabs/rackspace-python...\n",
       "3   0.722229  https://github.com/rfk/threading2/blob/7ec234d...\n",
       "4   0.713473  https://github.com/calston/rhumba/blob/05e3cbf...\n",
       "5   0.705459  https://github.com/istresearch/scrapy-cluster/...\n",
       "6   0.705304  https://github.com/calston/rhumba/blob/05e3cbf...\n",
       "7   0.703363  https://github.com/limpyd/redis-limpyd-jobs/bl...\n",
       "8   0.700093  https://github.com/calston/rhumba/blob/05e3cbf...\n",
       "9   0.697995  https://github.com/axialmarket/fsq/blob/43b84c...\n",
       "10  0.695321  https://github.com/ViiSiX/FlaskRedislite/blob/...\n",
       "11  0.694200  https://github.com/bioidiap/gridtk/blob/9e3291...\n",
       "12  0.693718  https://github.com/ejeschke/ginga/blob/a78c893...\n",
       "13  0.692426  https://github.com/knipknap/exscript/blob/7271...\n",
       "14  0.691984  https://github.com/closeio/tasktiger/blob/59f8..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_code(query, py_emb_mat, 5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0a644b",
   "metadata": {},
   "source": [
    "### We have now finished the construction of natural language embedding and code embedding individually. Switch to combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5a1761",
   "metadata": {},
   "source": [
    "# Combining the Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff1b451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the two functions will each return 3*k of result, if there are enough of them, \n",
    "# with weighted score of each. In this step we combine them through weighted score \n",
    "# and return the final k matches.\n",
    "def nlangCode(query, code_vecs, weight, k):\n",
    "    w1 = weight\n",
    "    w2 = 1-w1\n",
    "    df1 = weighted_doc(query, k, w1)\n",
    "    df2 = weighted_code(query, code_vecs, k, w2)\n",
    "    \n",
    "    # join df1 and df2.\n",
    "    combined = df1.merge(df2, how='outer', left_on='url', right_on='url').fillna(0)\n",
    "    combined['avg_score'] = combined['score_x'] + combined['score_y']\n",
    "    combined.sort_values(by='avg_score', inplace=True, ascending = False)\n",
    "    \n",
    "    combined['query']=[query for _ in range(len(combined))]\n",
    "    combined['language'] = ['Python' for _ in range(len(combined))]\n",
    "    return combined[:k][['language', 'query', 'url']]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc98e398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>query</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Python</td>\n",
       "      <td>priority queue</td>\n",
       "      <td>https://github.com/hubo1016/vlcp/blob/23905522...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Python</td>\n",
       "      <td>priority queue</td>\n",
       "      <td>https://github.com/fchauvel/MAD/blob/806d51748...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Python</td>\n",
       "      <td>priority queue</td>\n",
       "      <td>https://github.com/rackerlabs/rackspace-python...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Python</td>\n",
       "      <td>priority queue</td>\n",
       "      <td>https://github.com/rfk/threading2/blob/7ec234d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Python</td>\n",
       "      <td>priority queue</td>\n",
       "      <td>https://github.com/calston/rhumba/blob/05e3cbf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Python</td>\n",
       "      <td>priority queue</td>\n",
       "      <td>https://github.com/istresearch/scrapy-cluster/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Python</td>\n",
       "      <td>priority queue</td>\n",
       "      <td>https://github.com/calston/rhumba/blob/05e3cbf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Python</td>\n",
       "      <td>priority queue</td>\n",
       "      <td>https://github.com/limpyd/redis-limpyd-jobs/bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Python</td>\n",
       "      <td>priority queue</td>\n",
       "      <td>https://github.com/calston/rhumba/blob/05e3cbf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Python</td>\n",
       "      <td>priority queue</td>\n",
       "      <td>https://github.com/axialmarket/fsq/blob/43b84c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   language           query                                                url\n",
       "10   Python  priority queue  https://github.com/hubo1016/vlcp/blob/23905522...\n",
       "11   Python  priority queue  https://github.com/fchauvel/MAD/blob/806d51748...\n",
       "12   Python  priority queue  https://github.com/rackerlabs/rackspace-python...\n",
       "13   Python  priority queue  https://github.com/rfk/threading2/blob/7ec234d...\n",
       "14   Python  priority queue  https://github.com/calston/rhumba/blob/05e3cbf...\n",
       "15   Python  priority queue  https://github.com/istresearch/scrapy-cluster/...\n",
       "16   Python  priority queue  https://github.com/calston/rhumba/blob/05e3cbf...\n",
       "9    Python  priority queue  https://github.com/limpyd/redis-limpyd-jobs/bl...\n",
       "17   Python  priority queue  https://github.com/calston/rhumba/blob/05e3cbf...\n",
       "18   Python  priority queue  https://github.com/axialmarket/fsq/blob/43b84c..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlangCode(query, py_emb_mat, 0.0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b6d7e",
   "metadata": {},
   "source": [
    "# Evaluation - Using relevanceeval.py in CodeSearchNet \n",
    "Source Code:\n",
    "- https://github.com/github/CodeSearchNet/blob/master/src/relevanceeval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f52b89a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_py = merged_py[['Language', 'Query', 'GitHubUrl', 'Relevance', 'Notes']]\n",
    "annotation_py.to_csv('annotation_py.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e11a9522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the prediction results csv\n",
    "queries = pd.read_csv('queries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8032e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "## grid search for best weight dstribution\n",
    "def best_weights():\n",
    "    best_param = -1\n",
    "    best_score = -1\n",
    "    \n",
    "    thresholds = np.linspace(0.015,0.025,10)\n",
    "    for thres in thresholds:\n",
    "        out_dfs = []\n",
    "        for query in queries['query'].values:\n",
    "            out_df = nlangCode(query, py_emb_mat, thres, 10) #py_codebert(query, code_vecs, 10)\n",
    "            out_dfs.append(out_df)\n",
    "        trainset_result = pd.concat(out_dfs, ignore_index=True)\n",
    "        trainset_result.to_csv('train_py_result.csv')\n",
    "    \n",
    "        result = !python relevanceeval.py annotationStore.csv train_py_result.csv\n",
    "        ndcg = float(result[5].split()[1])\n",
    "\n",
    "        if ndcg > best_score:\n",
    "            best_score = ndcg\n",
    "            best_param = thres\n",
    "    return best_param, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2973f862",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "605407c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.017222222222222222, 0.314)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_weight, best_ndcg = best_weights()\n",
    "best_weight, best_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee0917e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>query</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python</td>\n",
       "      <td>convert int to string</td>\n",
       "      <td>https://github.com/tensorflow/datasets/blob/46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python</td>\n",
       "      <td>convert int to string</td>\n",
       "      <td>https://github.com/django-treebeard/django-tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python</td>\n",
       "      <td>convert int to string</td>\n",
       "      <td>https://github.com/romankoblov/leaf/blob/e042d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python</td>\n",
       "      <td>convert int to string</td>\n",
       "      <td>https://github.com/django-treebeard/django-tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python</td>\n",
       "      <td>convert int to string</td>\n",
       "      <td>https://github.com/tensorflow/datasets/blob/46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>Python</td>\n",
       "      <td>how to read .csv file in an efficient way?</td>\n",
       "      <td>https://github.com/Erotemic/utool/blob/3b27e1f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Python</td>\n",
       "      <td>how to read .csv file in an efficient way?</td>\n",
       "      <td>https://github.com/gem/oq-engine/blob/8294553a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>Python</td>\n",
       "      <td>how to read .csv file in an efficient way?</td>\n",
       "      <td>https://github.com/lappis-unb/salic-ml/blob/1b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>Python</td>\n",
       "      <td>how to read .csv file in an efficient way?</td>\n",
       "      <td>https://github.com/dshean/pygeotools/blob/5ac7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>Python</td>\n",
       "      <td>how to read .csv file in an efficient way?</td>\n",
       "      <td>https://github.com/draperjames/qtpandas/blob/6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    language                                       query  \\\n",
       "0     Python                       convert int to string   \n",
       "1     Python                       convert int to string   \n",
       "2     Python                       convert int to string   \n",
       "3     Python                       convert int to string   \n",
       "4     Python                       convert int to string   \n",
       "..       ...                                         ...   \n",
       "985   Python  how to read .csv file in an efficient way?   \n",
       "986   Python  how to read .csv file in an efficient way?   \n",
       "987   Python  how to read .csv file in an efficient way?   \n",
       "988   Python  how to read .csv file in an efficient way?   \n",
       "989   Python  how to read .csv file in an efficient way?   \n",
       "\n",
       "                                                   url  \n",
       "0    https://github.com/tensorflow/datasets/blob/46...  \n",
       "1    https://github.com/django-treebeard/django-tre...  \n",
       "2    https://github.com/romankoblov/leaf/blob/e042d...  \n",
       "3    https://github.com/django-treebeard/django-tre...  \n",
       "4    https://github.com/tensorflow/datasets/blob/46...  \n",
       "..                                                 ...  \n",
       "985  https://github.com/Erotemic/utool/blob/3b27e1f...  \n",
       "986  https://github.com/gem/oq-engine/blob/8294553a...  \n",
       "987  https://github.com/lappis-unb/salic-ml/blob/1b...  \n",
       "988  https://github.com/dshean/pygeotools/blob/5ac7...  \n",
       "989  https://github.com/draperjames/qtpandas/blob/6...  \n",
       "\n",
       "[990 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d8daf",
   "metadata": {},
   "source": [
    "### Result for doc embedding only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4662f492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of URLs in predictions that exist in the annotation dataset:\r\n",
      "\tpython: 7.18%\r\n",
      "% of URLs in predictions that exist in the annotation dataset (avg relevance > 0):\r\n",
      "\tpython: 7.85%\r\n",
      "NDCG:\r\n",
      "\tpython: 0.171\r\n",
      "NDCG (full ranking):\r\n",
      "\tpython: 0.114\r\n"
     ]
    }
   ],
   "source": [
    "out_dfs = []\n",
    "for query in queries['query'].values:\n",
    "    out_df = nlangCode(query, py_emb_mat, 1, 10) \n",
    "    out_dfs.append(out_df)\n",
    "trainset_result = pd.concat(out_dfs, ignore_index=True)\n",
    "trainset_result.to_csv('train_py_result.csv')\n",
    "\n",
    "!python relevanceeval.py annotationStore.csv train_py_result.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce641644",
   "metadata": {},
   "source": [
    "### Result for code embedding only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd74abc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of URLs in predictions that exist in the annotation dataset:\r\n",
      "\tpython: 15.87%\r\n",
      "% of URLs in predictions that exist in the annotation dataset (avg relevance > 0):\r\n",
      "\tpython: 17.18%\r\n",
      "NDCG:\r\n",
      "\tpython: 0.307\r\n",
      "NDCG (full ranking):\r\n",
      "\tpython: 0.218\r\n"
     ]
    }
   ],
   "source": [
    "out_dfs = []\n",
    "for query in queries['query'].values:\n",
    "    out_df = nlangCode(query, py_emb_mat, 0, 10) \n",
    "    out_dfs.append(out_df)\n",
    "trainset_result = pd.concat(out_dfs, ignore_index=True)\n",
    "trainset_result.to_csv('train_py_result.csv')\n",
    "\n",
    "!python relevanceeval.py annotationStore.csv train_py_result.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788dc679",
   "metadata": {},
   "source": [
    "- A combination of the two embeddings with 0.017222 on doc-embedding and 0.82778 on code-embedding results in an nDCG score of 0.314, higher than that of two individual embeddings which are 0.171 abd 0.307 respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8ee43a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
